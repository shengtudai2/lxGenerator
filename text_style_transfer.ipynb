{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ac8ff1",
   "metadata": {},
   "source": [
    "# CycleGAN网络实现文本风格迁移\n",
    "\n",
    "## 项目介绍\n",
    "\n",
    "本项目旨在使用CycleGAN模型实现文本风格迁移（Text Style Transfer）任务。模型使用Transformer网络作为生成器，CNN作为判别器。文本风格迁移中的风格与图像风格迁移中的相比，其范围显然要宽泛许多，从词汇分布、组织结构到情感色彩、身份特征等方面的差异都可以认为是文本风格的一部分。因此，文本风格迁移在未来的应用形式和场景非常多样与充满想象力。另外，由于文本相比于图像是离散数据，文本风格迁移在梯度传递方面存在困难。目前，因为缺乏具有强有力数学基础的代表作，该领域发展前景十分广阔。\n",
    "\n",
    "## 项目目的\n",
    "\n",
    "+ 熟悉掌握使用MindSpore框架进行深度学习模型的构建和训练\n",
    "+ 掌握Transformer模型的基本结构和编程方法\n",
    "+ 掌握使用CycleGAN模型进行中文文本风格迁移\n",
    "+ 掌握开源项目的发布流程\n",
    "\n",
    "## 项目环境\n",
    "\n",
    "+ MindSpore 1.7.0\n",
    "+ Python 3.8\n",
    "+ GPU RTX 3090\n",
    "+ Ubuntu 20.04\n",
    "\n",
    "## 实验步骤\n",
    "\n",
    "### 数据准备\n",
    "\n",
    "+ 选用鲁迅小说集作为目标域，从url下载txt格式文件\n",
    "+ 选用网络作文作为假样本域\n",
    "+ 去除下标、脚注和特殊符号等（不包括逗号和句号，作为分隔符）\n",
    "+ 使用HanLP分词，将文本段落分割为词汇，以空格区分\n",
    "+ 由于短文本风格不明显，以分隔符起始和结尾，截取符合长度要求的最长文本\n",
    "+ 将文本按行保存为数据集\n",
    "\n",
    "### 数据预处理\n",
    "\n",
    "+ 按照8：2的比例分割为训练数据和测试数据\n",
    "+ 使用北师大的CWV文学作品数据集将词汇转换为词向量\n",
    "\n",
    "### 训练网络\n",
    "\n",
    "训练网络代码梳理概况如下所示：\n",
    "\n",
    "```{python}\n",
    "Class CycleGanModel\n",
    "- Class TransformerGenerator\n",
    "    - Class TransformerEncoder\n",
    "        - Class EncoderCell\n",
    "            - Class SelfAttention\n",
    "            - Class FeedForward\n",
    "        - Class DecoderCell\n",
    "            - Class SelfAttention\n",
    "            - Class Encoder-Decoder Attention\n",
    "            - Class FeedForward\n",
    "    - Class TransformerDecoder\n",
    "- Class CnnDiscriminator\n",
    "```\n",
    "\n",
    "![Text Style Transfer](https://camo.githubusercontent.com/2a04777c752f76cc317eb2a258268f37565646fd990e6f6bcaaa44d06e996333/68747470733a2f2f692e696d6775722e636f6d2f55724c523971532e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099a873",
   "metadata": {},
   "source": [
    "## Transformer Generator\n",
    "\n",
    "我们首先完成transformer模型的编写，这一部分的难点在于不熟悉的API多，许多torch和mindspore之间的转换我们并不熟悉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852adb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import mindspore as ms\n",
    "from mindspore import Tensor\n",
    "from mindspore import ops\n",
    "from mindspore import nn\n",
    "from mindspore.common.initializer import initializer, XavierUniform\n",
    "from mindspore.ops import functional as F\n",
    "# from mindspore.ops import operations as P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a4502",
   "metadata": {},
   "source": [
    "swap是我们编写的一个小的辅助函数，这是由于torch和mindspore的转置函数的接收参数不同。这一部分代码我们完成了attention操作和mask操作。这里值得注意的是torch的matmul函数与mindspore的MatMul不同，它更像是MatMul与BatchMatMul的结合体。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11539e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap(shape, pos1, pos2):\n",
    "    list = [pos for pos in range(len(shape))]\n",
    "    list[pos1], list[pos2] = list[pos2], list[pos1]\n",
    "    return list\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return Tensor.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    matmul = ops.BatchMatMul()\n",
    "    softmax = ops.Softmax()\n",
    "    d_k = query.shape[-1]\n",
    "    scores = matmul(query, key.transpose(swap(key.shape, -2, -1))) / math.sqrt(d_k)\n",
    "\n",
    "\n",
    "if mask is not None:\n",
    "    scores = scores.masked_fill(mask, -1e9)\n",
    "p_attn = softmax(scores)\n",
    "if dropout is not None:\n",
    "    p_attn = dropout(p_attn)\n",
    "return matmul(p_attn, value), p_attn\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.CellList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab12ea4",
   "metadata": {},
   "source": [
    "这里我们遇到了两个小问题，一是mindspore无法像pytorch一样集中对神经网络进行参数初始化，所以要在每一层使用init进行初始化操作；而是init中输入shape与全连接层的shape是互为转置的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0238b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Cell):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        weight_init = initializer(XavierUniform(), [d_model, d_model], ms.float32)\n",
    "        self.linears = clones(nn.Dense(d_model, d_model, weight_init), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(keep_prob=dropout)\n",
    "\n",
    "    def construct(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            expand_dims = ops.ExpandDims()\n",
    "            mask = expand_dims(mask, 1)\n",
    "        nbatches = query.shape[0]\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = [l(x).view((nbatches, -1, self.h, self.d_k)).transpose((0, 2, 1, 3)) for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "    # 2) Apply attention on all the projected vectors in batch.\n",
    "    x, self.attn = attention(query, key, value, mask=mask,\n",
    "                             dropout=self.dropout)\n",
    "    # 3) \"Concat\" using a view and apply a final linear.\n",
    "    x = x.transpose(swap(x.shape, 1, 2)).view(nbatches, -1, self.h * self.d_k)\n",
    "return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a301d83c",
   "metadata": {},
   "source": [
    "这里实现了归一化层和RES层，这里发现了有趣的一点：Tensor的mean和std操作关键词分别用了keep_dims和keepdims。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867e3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Cell):\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = ms.Parameter(Tensor(np.ones(features), ms.float32))\n",
    "        self.b_2 = ms.Parameter(Tensor(np.zeros(features), ms.float32))\n",
    "        self.eps = eps\n",
    "\n",
    "    def construct(self, x):\n",
    "        mean = x.mean(-1, keep_dims=True)\n",
    "        std = x.std(-1, keepdims=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "class SublayerConnection(nn.Cell):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def construct(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm.construct(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86e03f",
   "metadata": {},
   "source": [
    "这里实现了位置编码与编码解码层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50bd6462",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Cell):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        # weight_init for Dense: (out_channels, in_channels)\n",
    "        weight_init_1 = initializer(XavierUniform(), [d_model, d_ff], ms.float32)\n",
    "        weight_init_2 = initializer(XavierUniform(), [d_ff, d_model], ms.float32)\n",
    "        self.w_1 = nn.Dense(d_model, d_ff, weight_init_2)\n",
    "        self.w_2 = nn.Dense(d_ff, d_model, weight_init_1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def construct(self, x):\n",
    "        relu = ops.ReLU()\n",
    "        return self.w_2(self.dropout(relu(self.w_1(x))))\n",
    "\n",
    "class EncoderLayer(nn.Cell):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def construct(self, x, mask):\n",
    "        x = self.sublayer[0].construct(x, lambda x: self.self_attn.construct(x, x, x, mask))\n",
    "        return self.sublayer[1].construct(x, self.feed_forward.construct)\n",
    "\n",
    "class DecoderLayer(nn.Cell):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "\n",
    "    def construct(self, x, memory, src_mask, tgt_mask):\n",
    "        m = memory\n",
    "        x = self.sublayer[0].construct(x, lambda x: self.self_attn.construct(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1].construct(x, lambda x: self.src_attn.construct(x, m, m, src_mask))\n",
    "        return self.sublayer[2].construct(x, self.feed_forward.construct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8eb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Cell):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)  # layer = EncoderLayer()\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def construct(self, x, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer.construct(x, mask)\n",
    "        return self.norm.construct(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Cell):\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def construct(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer.construct(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm.construct(x)\n",
    "\n",
    "\n",
    "class FullEncoder(nn.Cell):\n",
    "    def __init__(self, encoder, src_embed):\n",
    "        super(FullEncoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed  # Embedding function\n",
    "\n",
    "    def construct(self, src, src_mask):\n",
    "        return self.encoder.construct(self.src_embed(src), src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0bd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scale(nn.Cell):\n",
    "    def __init__(self, d_model):\n",
    "        super(Scale, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def construct(self, x):\n",
    "        return x * math.sqrt(self.d_model)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Cell):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = Tensor(np.zeros((max_len, d_model)), ms.float32)\n",
    "        expand_dims = ops.ExpandDims()\n",
    "        cast = ops.Cast()\n",
    "        exp = ops.Exp()\n",
    "        sin = ops.Sin()\n",
    "        cos = ops.Cos()\n",
    "        position = cast(expand_dims(ms.numpy.arange(0, max_len), 1), ms.float32)\n",
    "        div_term = exp(cast(ms.numpy.arange(0, d_model, 2), ms.float32) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = sin(position * div_term)\n",
    "        pe[:, 1::2] = cos(position * div_term)\n",
    "        self.pe = expand_dims(pe, 0)  # this is not trainable parameters\n",
    "\n",
    "    def construct(self, x):\n",
    "        cast = ops.Cast()\n",
    "        x = cast(x, ms.float32) + self.pe[:, :x.shape[1]]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1165f7c",
   "metadata": {},
   "source": [
    "生成器与编解码器。这里有一点很有趣，当使用特定的激活函数时，求解梯度时会报错，因此，原本打算在这里使用Gumbel Softmax的想法被放弃。另外，即使我重写了construct方法，依然无法通过out=Net(input)的形式搭建网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8170804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Cell):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        weight_init = initializer(XavierUniform(), [vocab, d_model], ms.float32)\n",
    "        self.proj = nn.Dense(d_model, vocab, weight_init)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def _construct(self, x):\n",
    "        log_softmax = nn.LogSoftmax()\n",
    "        return log_softmax(self.proj(x))\n",
    "\n",
    "    def construct(self, x, scale=1.0):\n",
    "        return self.softmax(self.proj(x) * scale)\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Cell):\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed  # Embedding function\n",
    "        self.tgt_embed = tgt_embed  # Embedding function\n",
    "        self.generator = generator\n",
    "\n",
    "    def construct(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                           tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder.construct(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder.construct(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
    "\n",
    "    def Transformer(self, N=6, d_model=1024, d_ff=2048, h=8, dropout=0.1):\n",
    "        \"Helper: Construct a model from hyperparameters.\"\n",
    "        c = copy.deepcopy\n",
    "        attn = MultiHeadedAttention(h, d_model)\n",
    "        ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        position = PositionalEncoding(d_model, dropout)\n",
    "        model = EncoderDecoder(\n",
    "            Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "            Decoder(DecoderLayer(d_model, c(attn), c(attn),\n",
    "                                 c(ff), dropout), N),\n",
    "            nn.SequentialCell(Scale(d_model), c(position)),\n",
    "            nn.SequentialCell(Scale(d_model), c(position)), None)\n",
    "        # This was important from their code.\n",
    "        # Initialize parameters with Glorot / fan_avg.\n",
    "        # We do this in each Dense Layer.\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5148d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        expand_dims = ops.ExpandDims()\n",
    "        self.src_mask = expand_dims((src != pad), -2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
    "        self.ntokens = (self.trg_y != pad).sum()\n",
    "\n",
    "@staticmethod\n",
    "def make_std_mask(tgt, pad):\n",
    "    \"Create a mask to hide padding and future words.\"\n",
    "    expand_dims = ops.ExpandDims()\n",
    "    tgt_mask = expand_dims((tgt != pad), -2)\n",
    "    logical_and = ops.LogicalAnd()\n",
    "    tgt_mask = logical_and(tgt_mask, Tensor(subsequent_mask(tgt.shape[-1]), tgt_mask.dtype))\n",
    "    return tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277dec5",
   "metadata": {},
   "source": [
    "我们使用了与DCGAN中类似的方式，将求解过程使用类进行了封装。由于前面提到的无法调用实例搭建网络的问题，这里我将nn中TrainOneStepCell类进行了继承和改写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d7771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainOneStepCell(nn.TrainOneStepCell):\n",
    "    def construct(self, *inputs):\n",
    "        loss = self.network.construct(*inputs)\n",
    "        sens = F.fill(loss.dtype, loss.shape, self.sens)\n",
    "        grads = self.grad(self.network, self.weights)(*inputs, sens)\n",
    "        grads = self.grad_reducer(grads)\n",
    "        loss = F.depend(loss, self.optimizer(grads))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class WithLossGenerator(nn.Cell):\n",
    "    def __init__(self, generator, criterion):\n",
    "        super(WithLossGenerator, self).__init__(auto_prefix=True)\n",
    "        self.netG = generator\n",
    "        self.loss_fn = criterion\n",
    "\n",
    "    def construct(self, z, y, norm):\n",
    "        x = self.netG.construct(z)\n",
    "        cast = ops.Cast()\n",
    "        print(x.view(-1, x.shape[-1]), y.view(-1))\n",
    "        loss = self.loss_fn(x.view(-1), y.view(-1)) / cast(norm, ms.float32)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SimpleLossCompute(nn.Cell):\n",
    "    def __init__(self, generator, criterion, optimizer):\n",
    "        super(SimpleLossCompute, self).__init__()\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.netG_with_criterion = WithLossGenerator(generator,\n",
    "                                                     criterion)\n",
    "        self.myTrainOneStepForG = TrainOneStepCell(\n",
    "            self.netG_with_criterion,\n",
    "            self.optimizer)\n",
    "\n",
    "    def __call__(self, z, y, norm):\n",
    "        output_G = self.myTrainOneStepForG(z, y, norm).view(-1)\n",
    "        cast = ops.Cast()\n",
    "        netG_loss = output_G * cast(norm, ms.float32)\n",
    "        return netG_loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf67ec79",
   "metadata": {},
   "source": [
    "由于原方法中使用了<Attention Is All You Need>中的动量优化算子求解梯度下降，我重写了NoamLR方法，将它传入Adam的lr中，实现了对原方法的优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7531e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoamLR(model_size, factor, warmup, total_step):\n",
    "    lr = []\n",
    "    for step in range(total_step):\n",
    "        step += 1\n",
    "        lr.append(factor * model_size ** (-0.5) *\n",
    "                  min(step ** (-0.5), step * warmup ** (-1.5)))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a22f71",
   "metadata": {},
   "source": [
    "## CNN Discriminator\n",
    "\n",
    "![Transformer and CNN](https://camo.githubusercontent.com/b11215e59ec0d1c6369c8dfc85664f438e52d46b101362acf81281fdbc97338f/68747470733a2f2f692e696d6775722e636f6d2f746d4d6976496d2e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b30de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import create_dict_iterator\n",
    "\n",
    "class Resblock(nn.Cell):\n",
    "    def __init__(self, inner_dim, kernel_size):\n",
    "        super(Resblock, self).__init__()\n",
    "        self.inner_dim = inner_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.relu = ops.ReLU()\n",
    "        if kernel_size % 2 != 1:\n",
    "            raise Exception(\"kernel size must be odd number!\")\n",
    "        self.conv_1 = nn.Conv1d(self.inner_dim, self.inner_dim, self.kernel_size, pad_mode=\"pad\",\n",
    "                                padding=int((kernel_size - 1) / 2))\n",
    "        self.conv_2 = nn.Conv1d(self.inner_dim, self.inner_dim, self.kernel_size, pad_mode=\"pad\",\n",
    "                                padding=int((kernel_size - 1) / 2))\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        output = self.relu(inputs)\n",
    "        output = self.conv_1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.conv_2(output)\n",
    "        return inputs + (0.3 * output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7ddd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Cell):\n",
    "    def __init__(self, word_dim, inner_dim, seq_len, kernel_size=3, two_out=False):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.word_dim = word_dim\n",
    "        self.inner_dim = inner_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.kernel_size = kernel_size\n",
    "        if kernel_size % 2 != 1:\n",
    "            raise Exception(\"kernel size must be odd number!\")\n",
    "        self.conv_1 = nn.Conv1d(self.word_dim, self.inner_dim, self.kernel_size, pad_mode=\"pad\",\n",
    "                                padding=int((kernel_size - 1) / 2))\n",
    "        self.resblock_1 = Resblock(inner_dim, kernel_size)\n",
    "        self.resblock_2 = Resblock(inner_dim, kernel_size)\n",
    "        self.resblock_3 = Resblock(inner_dim, kernel_size)\n",
    "        self.resblock_4 = Resblock(inner_dim, kernel_size)\n",
    "        W = seq_len * inner_dim\n",
    "        self.fc_1 = nn.Dense(W, int(W / 8))\n",
    "        self.fc_2 = nn.Dense(int(W / 8), int(W / 32))\n",
    "        self.fc_3 = nn.Dense(int(W / 32), int(W / 64))\n",
    "        self.fc_4 = nn.Dense(int(W / 64), 2 if two_out else 1)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "\n",
    "    def feed_fc(self, inputs):\n",
    "        output = self.relu(self.fc_1(inputs))\n",
    "        output = self.relu(self.fc_2(output))\n",
    "        output = self.relu(self.fc_3(output))\n",
    "        return self.fc_4(output)\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        this_bs = inputs.shape[0]\n",
    "        permute = ops.Transpose()\n",
    "        inputs = ops.Cast()(permute(inputs, (0, 2, 1)), ms.float32)\n",
    "        if inputs.shape[-1] != self.seq_len:\n",
    "            # print(\"Warning: seq_len(%d) != fixed_seq_len(%d), auto-pad.\"%(inputs.shape[-1], self.seq_len))\n",
    "            p1d = (0, self.seq_len - inputs.shape[-1])\n",
    "            inputs = F.pad(inputs, p1d, \"constant\", 0)\n",
    "            # print(\"after padding,\", inputs.shape)\n",
    "        output = self.conv_1(inputs)\n",
    "        output = self.resblock_1(output)\n",
    "        output = self.resblock_2(output)\n",
    "        output = self.resblock_3(output)\n",
    "        output = self.resblock_4(output)\n",
    "        output = output.view(this_bs, -1)\n",
    "        # print(output.shape)\n",
    "        return self.feed_fc(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e469b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithLossCellD(nn.Cell):\n",
    "    def __init__(self, netD, loss_fn):\n",
    "        super(WithLossCellD, self).__init__(auto_prefix=True)\n",
    "        self.netD = netD\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, z, y):\n",
    "        x = self.netD.construct(z)\n",
    "        cast = ops.Cast()\n",
    "        loss = self.loss_fn(x.view(-1), y.view(-1))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class CLA(nn.Cell):\n",
    "    def __init__(self, myTrainOneStepCellForD):\n",
    "        super(CLA, self).__init__(auto_prefix=True)\n",
    "        self.myTrainOneStepCellForD = myTrainOneStepCellForD\n",
    "\n",
    "    def construct(self, data, label):\n",
    "        output_D = self.myTrainOneStepCellForD(data, label).view(-1)\n",
    "        netD_loss = output_D.mean()\n",
    "        return netD_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f45fa2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.set_context(mode=ms.GRAPH_MODE, device_target=\"GPU\")\n",
    "data_root = \"./datasets\"  # 数据集根目录\n",
    "batch_size = 128  # 批量大小\n",
    "word_dim = 300  # 词向量大小\n",
    "inner_dim = 1024  # 隐藏层大小\n",
    "seq_len = 40  # 句子长度\n",
    "num_epochs = 10  # 训练周期数\n",
    "size = 500  # 数据集大小\n",
    "lr = 0.0002  # 学习率\n",
    "beta1 = 0.5  # Adam优化器的beta1超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "007040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = Discriminator(word_dim, inner_dim, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6191c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss(reduction='mean')\n",
    "optimizerD = nn.Adam(netD.trainable_params(), learning_rate=lr, beta1=beta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5803188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "netD_with_criterion = WithLossCellD(netD, loss)\n",
    "myTrainOneStepCellForD = TrainOneStepCell(netD_with_criterion, optimizerD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98967f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[ 1/10][  1/500]   Loss_D:    nan\n",
      "[ 1/10][ 51/500]   Loss_D: 0.7354\n",
      "[ 1/10][101/500]   Loss_D: 0.9072\n",
      "[ 1/10][151/500]   Loss_D: 0.7850\n",
      "[ 1/10][201/500]   Loss_D: 0.7923\n",
      "[ 1/10][251/500]   Loss_D: 0.7538\n",
      "[ 1/10][301/500]   Loss_D: 0.8825\n",
      "[ 1/10][351/500]   Loss_D: 0.8753\n",
      "[ 1/10][401/500]   Loss_D: 0.7697\n",
      "[ 1/10][451/500]   Loss_D: 0.8455\n",
      "[ 1/10][500/500]   Loss_D: 0.7035\n",
      "[ 2/10][  1/500]   Loss_D: 0.7812\n",
      "[ 2/10][ 51/500]   Loss_D: 0.7747\n",
      "[ 2/10][101/500]   Loss_D: 0.7750\n",
      "[ 2/10][151/500]   Loss_D: 0.8097\n",
      "[ 2/10][201/500]   Loss_D: 0.8195\n",
      "[ 2/10][251/500]   Loss_D: 0.8614\n",
      "[ 2/10][301/500]   Loss_D: 0.8115\n",
      "[ 2/10][351/500]   Loss_D: 0.8399\n",
      "[ 2/10][401/500]   Loss_D: 0.7533\n",
      "[ 2/10][451/500]   Loss_D: 0.7543\n",
      "[ 2/10][500/500]   Loss_D: 0.8703\n",
      "[ 3/10][  1/500]   Loss_D: 0.8474\n",
      "[ 3/10][ 51/500]   Loss_D: 0.7911\n",
      "[ 3/10][101/500]   Loss_D: 0.7963\n",
      "[ 3/10][151/500]   Loss_D: 0.8944\n",
      "[ 3/10][201/500]   Loss_D: 0.8241\n",
      "[ 3/10][251/500]   Loss_D: 0.8194\n",
      "[ 3/10][301/500]   Loss_D: 0.7950\n",
      "[ 3/10][351/500]   Loss_D: 0.7507\n",
      "[ 3/10][401/500]   Loss_D: 0.7786\n",
      "[ 3/10][451/500]   Loss_D: 0.8421\n",
      "[ 3/10][500/500]   Loss_D: 0.8021\n",
      "[ 4/10][  1/500]   Loss_D: 0.8385\n",
      "[ 4/10][ 51/500]   Loss_D: 0.7561\n",
      "[ 4/10][101/500]   Loss_D: 0.7861\n",
      "[ 4/10][151/500]   Loss_D: 0.7834\n",
      "[ 4/10][201/500]   Loss_D: 0.7588\n",
      "[ 4/10][251/500]   Loss_D: 0.7460\n",
      "[ 4/10][301/500]   Loss_D: 0.8157\n",
      "[ 4/10][351/500]   Loss_D: 0.8265\n",
      "[ 4/10][401/500]   Loss_D: 0.7231\n",
      "[ 4/10][451/500]   Loss_D: 0.8531\n",
      "[ 4/10][500/500]   Loss_D: 0.8016\n",
      "[ 5/10][  1/500]   Loss_D: 0.8862\n",
      "[ 5/10][ 51/500]   Loss_D: 0.7993\n",
      "[ 5/10][101/500]   Loss_D: 0.7669\n",
      "[ 5/10][151/500]   Loss_D: 0.7656\n",
      "[ 5/10][201/500]   Loss_D: 0.8608\n",
      "[ 5/10][251/500]   Loss_D: 0.7693\n",
      "[ 5/10][301/500]   Loss_D: 0.7632\n",
      "[ 5/10][351/500]   Loss_D: 0.8530\n",
      "[ 5/10][401/500]   Loss_D: 0.8546\n",
      "[ 5/10][451/500]   Loss_D: 0.7981\n",
      "[ 5/10][500/500]   Loss_D: 0.7741\n",
      "[ 6/10][  1/500]   Loss_D: 0.8254\n",
      "[ 6/10][ 51/500]   Loss_D: 0.7928\n",
      "[ 6/10][101/500]   Loss_D: 0.8065\n",
      "[ 6/10][151/500]   Loss_D: 0.8253\n",
      "[ 6/10][201/500]   Loss_D: 0.8755\n",
      "[ 6/10][251/500]   Loss_D: 0.7040\n",
      "[ 6/10][301/500]   Loss_D: 0.7840\n",
      "[ 6/10][351/500]   Loss_D: 0.8404\n",
      "[ 6/10][401/500]   Loss_D: 0.7814\n",
      "[ 6/10][451/500]   Loss_D: 0.8032\n",
      "[ 6/10][500/500]   Loss_D: 0.8397\n",
      "[ 7/10][  1/500]   Loss_D: 0.8081\n",
      "[ 7/10][ 51/500]   Loss_D: 0.7803\n",
      "[ 7/10][101/500]   Loss_D: 0.8544\n",
      "[ 7/10][151/500]   Loss_D: 0.8260\n",
      "[ 7/10][201/500]   Loss_D: 0.8119\n",
      "[ 7/10][251/500]   Loss_D: 0.8472\n",
      "[ 7/10][301/500]   Loss_D: 0.7282\n",
      "[ 7/10][351/500]   Loss_D: 0.7921\n",
      "[ 7/10][401/500]   Loss_D: 0.8476\n",
      "[ 7/10][451/500]   Loss_D: 0.8204\n",
      "[ 7/10][500/500]   Loss_D: 0.8346\n",
      "[ 8/10][  1/500]   Loss_D: 0.8012\n",
      "[ 8/10][ 51/500]   Loss_D: 0.7567\n",
      "[ 8/10][101/500]   Loss_D: 0.8853\n",
      "[ 8/10][151/500]   Loss_D: 0.7952\n",
      "[ 8/10][201/500]   Loss_D: 0.9428\n",
      "[ 8/10][251/500]   Loss_D: 0.8217\n",
      "[ 8/10][301/500]   Loss_D: 0.7585\n",
      "[ 8/10][351/500]   Loss_D: 0.6694\n",
      "[ 8/10][401/500]   Loss_D: 0.8467\n",
      "[ 8/10][451/500]   Loss_D: 0.7709\n",
      "[ 8/10][500/500]   Loss_D: 0.7951\n",
      "[ 9/10][  1/500]   Loss_D: 0.8669\n",
      "[ 9/10][ 51/500]   Loss_D: 0.8484\n",
      "[ 9/10][101/500]   Loss_D: 0.8384\n",
      "[ 9/10][151/500]   Loss_D: 0.9402\n",
      "[ 9/10][201/500]   Loss_D: 0.8065\n",
      "[ 9/10][251/500]   Loss_D: 0.7726\n",
      "[ 9/10][301/500]   Loss_D: 0.8736\n",
      "[ 9/10][351/500]   Loss_D: 0.7800\n",
      "[ 9/10][401/500]   Loss_D: 0.8088\n",
      "[ 9/10][451/500]   Loss_D: 0.8157\n",
      "[ 9/10][500/500]   Loss_D: 0.7598\n",
      "[10/10][  1/500]   Loss_D: 0.7924\n",
      "[10/10][ 51/500]   Loss_D: 0.7745\n",
      "[10/10][101/500]   Loss_D: 0.7004\n",
      "[10/10][151/500]   Loss_D: 0.7955\n",
      "[10/10][201/500]   Loss_D: 0.7634\n",
      "[10/10][251/500]   Loss_D: 0.8721\n",
      "[10/10][301/500]   Loss_D: 0.7556\n",
      "[10/10][351/500]   Loss_D: 0.7529\n",
      "[10/10][401/500]   Loss_D: 0.7615\n",
      "[10/10][451/500]   Loss_D: 0.8262\n",
      "[10/10][500/500]   Loss_D: 0.8451\n"
     ]
    }
   ],
   "source": [
    "cla = CLA(myTrainOneStepCellForD)\n",
    "cla.set_train()\n",
    "# 创建迭代器\n",
    "data_loader = create_dict_iterator(size * num_epochs, batch_size, seq_len, word_dim)\n",
    "D_losses = []\n",
    "# 开始循环训练\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # 为每轮训练读入数据\n",
    "    for i in range(size):\n",
    "        d = next(data_loader)\n",
    "        data = Tensor(d[\"data\"], ms.float32)\n",
    "        label = Tensor(d[\"label\"], ms.float32)\n",
    "        netD_loss = cla.construct(data, label)\n",
    "        if i % 50 == 0 or i == size - 1:\n",
    "            # 输出训练记录\n",
    "            print('[%2d/%d][%3d/%d]   Loss_D:%7.4f' % (\n",
    "                epoch + 1, num_epochs, i + 1, size, netD_loss.asnumpy()))\n",
    "        D_losses.append(netD_loss.asnumpy())\n",
    "# 保存网络模型参数为ckpt文件\n",
    "ms.save_checkpoint(netD, \"Discriminator.ckpt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}